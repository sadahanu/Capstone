{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from retrain import *\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test on google's image laerning using imagenet input file structure\n",
    "IMGDIR = \"/Users/zhouyu/Documents/Zhou_Yu/DS/Galvanize/Capstone_data/test_data_stan\"\n",
    "class Helper_FLAGS(object):\n",
    "    def __init__(self):\n",
    "        self.model_dir = \"./temp\"\n",
    "        self.image_dir = IMGDIR\n",
    "        self.testing_percentage = 10\n",
    "        self.validation_percentage = 10\n",
    "        self.flip_left_right = False\n",
    "        self.random_crop = False\n",
    "        self.random_scale = False\n",
    "        self.random_brightness = False\n",
    "        self.bottleneck_dir = './temp/bottleneck'\n",
    "        self.architecture = 'inception_v3'\n",
    "        self.final_tensor_name = 'final_result'\n",
    "        self.summaries_dir = './temp/retrain_logs'\n",
    "        self.how_many_training_steps = 10\n",
    "        self.train_batch_size = 32\n",
    "        self.eval_step_interval = 10\n",
    "        self.validation_batch_size = 32\n",
    "        self.intermediate_store_frequency = 0\n",
    "        self.intermediate_output_graphs_dir = \"./temp/intermediate_graph\"\n",
    "        self.print_misclassified_test_images = False\n",
    "        self.output_graph = './temp/output_graph.pb'\n",
    "        self.output_labels = './temp/output_labels.txt'\n",
    "        self.test_batch_size = -1\n",
    "zFLAGS = Helper_FLAGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNumjpegs(lst):\n",
    "    count = 0\n",
    "    for cat, vals in lst.iteritems():\n",
    "        count += len(vals['testing'])+len(vals['training'])+len(vals['validation'])\n",
    "    return count  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "model_info = create_model_info('inception_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bottleneck_tensor_name': 'pool_3/_reshape:0',\n",
       " 'bottleneck_tensor_size': 2048,\n",
       " 'data_url': 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz',\n",
       " 'input_depth': 3,\n",
       " 'input_height': 299,\n",
       " 'input_mean': 128,\n",
       " 'input_std': 128,\n",
       " 'input_width': 299,\n",
       " 'model_file_name': 'classify_image_graph_def.pb',\n",
       " 'resized_input_tensor_name': 'Mul:0'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "  # Set up the pre-trained graph.\n",
    "maybe_download_and_extract(model_info['data_url'])\n",
    "graph, bottleneck_tensor, resized_image_tensor = (create_model_graph(model_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Looking for images in 'Chihuahua'\n",
      "INFO:tensorflow:Looking for images in 'Shih-Tzu'\n"
     ]
    }
   ],
   "source": [
    "# Look at the folder structure, and create lists of all the images.\n",
    "image_lists = create_image_lists(zFLAGS.image_dir, zFLAGS.testing_percentage,\n",
    "                                   zFLAGS.validation_percentage)\n",
    "class_count = len(image_lists.keys())\n",
    "assert class_count>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " # See if the command-line flags mean we're applying any distortions.\n",
    "do_distort_images = should_distort_images(zFLAGS.flip_left_right, zFLAGS.random_crop, \n",
    "                                          zFLAGS.random_scale,zFLAGS.random_brightness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:2017-09-01 11:50:06.511387: Step 0: Train accuracy = 96.9%\n",
      "INFO:tensorflow:2017-09-01 11:50:06.514854: Step 0: Cross entropy = 0.532486\n",
      "INFO:tensorflow:2017-09-01 11:50:06.580539: Step 0: Validation accuracy = 100.0% (N=32)\n",
      "INFO:tensorflow:2017-09-01 11:50:06.899064: Step 9: Train accuracy = 100.0%\n",
      "INFO:tensorflow:2017-09-01 11:50:06.900300: Step 9: Cross entropy = 0.165419\n",
      "INFO:tensorflow:2017-09-01 11:50:06.959527: Step 9: Validation accuracy = 100.0% (N=32)\n",
      "training done, now testing....\n",
      "INFO:tensorflow:Final test accuracy = 100.0% (N=1)\n",
      "INFO:tensorflow:Froze 2 variables.\n",
      "Converted 2 variables to const ops.\n",
      "total 10 training for 44 images is 5.98612499237 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Set up the image decoding sub-graph.\n",
    "    jpeg_data_tensor, decoded_image_tensor = add_jpeg_decoding(\n",
    "        model_info['input_width'], model_info['input_height'],\n",
    "        model_info['input_depth'], model_info['input_mean'],\n",
    "        model_info['input_std'])\n",
    "\n",
    "    if do_distort_images:\n",
    "        # We will be applying distortions, so setup the operations we'll need.\n",
    "        (distorted_jpeg_data_tensor,\n",
    "         distorted_image_tensor) = add_input_distortions(\n",
    "           zFLAGS.flip_left_right, zFLAGS.random_crop, zFLAGS.random_scale,\n",
    "           zFLAGS.random_brightness, model_info['input_width'],\n",
    "           model_info['input_height'], model_info['input_depth'],\n",
    "           model_info['input_mean'], model_info['input_std'])\n",
    "    else:\n",
    "    # We'll make sure we've calculated the 'bottleneck' image summaries and\n",
    "      # cached them on disk.\n",
    "        cache_bottlenecks(sess, image_lists, zFLAGS.image_dir,\n",
    "                        zFLAGS.bottleneck_dir, jpeg_data_tensor,\n",
    "                        decoded_image_tensor, resized_image_tensor,\n",
    "                        bottleneck_tensor, zFLAGS.architecture)\n",
    "\n",
    "    # Add the new layer that we'll be training.\n",
    "    (train_step, cross_entropy, bottleneck_input, ground_truth_input,\n",
    "     final_tensor) = add_final_training_ops(\n",
    "         len(image_lists.keys()), zFLAGS.final_tensor_name, bottleneck_tensor,\n",
    "         model_info['bottleneck_tensor_size'])\n",
    "\n",
    "    # Create the operations we need to evaluate the accuracy of our new layer.\n",
    "    evaluation_step, prediction = add_evaluation_step(\n",
    "        final_tensor, ground_truth_input)\n",
    "\n",
    "    # Merge all the summaries and write them out to the summaries_dir\n",
    "    merged = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter(zFLAGS.summaries_dir + '/train',\n",
    "                                         sess.graph)\n",
    "\n",
    "    validation_writer = tf.summary.FileWriter(\n",
    "        zFLAGS.summaries_dir + '/validation')\n",
    "\n",
    "    # Set up all our weights to their initial default values.\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # Run the training for as many cycles as requested on the command line.\n",
    "    for i in range(zFLAGS.how_many_training_steps):\n",
    "    # Get a batch of input bottleneck values, either calculated fresh every\n",
    "      # time with distortions applied, or from the cache stored on disk.\n",
    "        if do_distort_images:\n",
    "            (train_bottlenecks,\n",
    "             train_ground_truth) = get_random_distorted_bottlenecks(\n",
    "             sess, image_lists, zFLAGS.train_batch_size, 'training',\n",
    "             zFLAGS.image_dir, distorted_jpeg_data_tensor,\n",
    "             distorted_image_tensor, resized_image_tensor, bottleneck_tensor)\n",
    "        else:\n",
    "            (train_bottlenecks,\n",
    "             train_ground_truth, _) = get_random_cached_bottlenecks(\n",
    "             sess, image_lists, zFLAGS.train_batch_size, 'training',\n",
    "             zFLAGS.bottleneck_dir, zFLAGS.image_dir, jpeg_data_tensor,\n",
    "             decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n",
    "             zFLAGS.architecture)\n",
    "    # Feed the bottlenecks and ground truth into the graph, and run a training\n",
    "    # step. Capture training summaries for TensorBoard with the `merged` op.\n",
    "        train_summary, _ = sess.run([merged, train_step],\n",
    "                                    feed_dict={bottleneck_input: train_bottlenecks,\n",
    "                                               ground_truth_input: train_ground_truth})\n",
    "        train_writer.add_summary(train_summary, i)\n",
    "\n",
    "    # Every so often, print out how well the graph is training.\n",
    "        is_last_step = (i + 1 == zFLAGS.how_many_training_steps)\n",
    "        if (i % zFLAGS.eval_step_interval) == 0 or is_last_step:\n",
    "            train_accuracy, cross_entropy_value = sess.run(\n",
    "                [evaluation_step, cross_entropy],\n",
    "                feed_dict={bottleneck_input: train_bottlenecks,\n",
    "                       ground_truth_input: train_ground_truth})\n",
    "            tf.logging.info('%s: Step %d: Train accuracy = %.1f%%' %\n",
    "                        (datetime.now(), i, train_accuracy * 100))\n",
    "            tf.logging.info('%s: Step %d: Cross entropy = %f' %\n",
    "                        (datetime.now(), i, cross_entropy_value))\n",
    "            validation_bottlenecks, validation_ground_truth, _ = (\n",
    "                get_random_cached_bottlenecks(\n",
    "                    sess, image_lists, zFLAGS.validation_batch_size, 'validation',\n",
    "                    zFLAGS.bottleneck_dir, zFLAGS.image_dir, jpeg_data_tensor,\n",
    "                    decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n",
    "                    zFLAGS.architecture))\n",
    "        # Run a validation step and capture training summaries for TensorBoard\n",
    "        # with the `merged` op.\n",
    "            validation_summary, validation_accuracy = sess.run(\n",
    "                [merged, evaluation_step],\n",
    "                feed_dict={bottleneck_input: validation_bottlenecks,\n",
    "                           ground_truth_input: validation_ground_truth})\n",
    "            validation_writer.add_summary(validation_summary, i)\n",
    "            tf.logging.info('%s: Step %d: Validation accuracy = %.1f%% (N=%d)' %\n",
    "                            (datetime.now(), i, validation_accuracy * 100,\n",
    "                             len(validation_bottlenecks)))\n",
    "\n",
    "        # Store intermediate results\n",
    "        intermediate_frequency = zFLAGS.intermediate_store_frequency\n",
    "\n",
    "        if (intermediate_frequency > 0 and (i % intermediate_frequency == 0)\n",
    "            and i > 0):\n",
    "            intermediate_file_name = (zFLAGS.intermediate_output_graphs_dir +\n",
    "                                  'intermediate_' + str(i) + '.pb')\n",
    "            tf.logging.info('Save intermediate result to : ' +\n",
    "                        intermediate_file_name)\n",
    "            save_graph_to_file(sess, graph, intermediate_file_name)\n",
    "    end_time = time.time()\n",
    "    print \"training done, now testing....\"\n",
    "    # We've completed all our training, so run a final test evaluation on\n",
    "    # some new images we haven't used before.\n",
    "    test_bottlenecks, test_ground_truth, test_filenames = (\n",
    "        get_random_cached_bottlenecks(\n",
    "            sess, image_lists, zFLAGS.test_batch_size, 'testing',\n",
    "            zFLAGS.bottleneck_dir, zFLAGS.image_dir, jpeg_data_tensor,\n",
    "            decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n",
    "            zFLAGS.architecture))\n",
    "    test_accuracy, predictions = sess.run(\n",
    "        [evaluation_step, prediction],\n",
    "        feed_dict={bottleneck_input: test_bottlenecks,\n",
    "                   ground_truth_input: test_ground_truth})\n",
    "    tf.logging.info('Final test accuracy = %.1f%% (N=%d)' %\n",
    "                    (test_accuracy * 100, len(test_bottlenecks)))\n",
    "\n",
    "    if zFLAGS.print_misclassified_test_images:\n",
    "        tf.logging.info('=== MISCLASSIFIED TEST IMAGES ===')\n",
    "        for i, test_filename in enumerate(test_filenames):\n",
    "            if predictions[i] != test_ground_truth[i].argmax():\n",
    "                tf.logging.info('%70s  %s' %\n",
    "                          (test_filename,\n",
    "                           list(image_lists.keys())[predictions[i]]))\n",
    "\n",
    "    # Write out the trained graph and labels with the weights stored as\n",
    "    # constants.\n",
    "    save_graph_to_file(sess, graph, zFLAGS.output_graph)\n",
    "    with gfile.FastGFile(zFLAGS.output_labels, 'w') as f:\n",
    "        f.write('\\n'.join(image_lists.keys()) + '\\n')\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, \"my_model\")\n",
    "print \"total 10 training for {} images is {} s\".format(getNumjpegs(image_lists), end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
